{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "900c37c1",
   "metadata": {},
   "source": [
    "**For Fine-tuning**\n",
    "===\n",
    "> -*- coding: utf-8 -*-\n",
    "\n",
    "> Author: xinghd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d137c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import Trainer, Predictor, TrainReader,TestReader,PredictReader, data_collate, get_shuffle_data, collate_fn, seed_everything\n",
    "from model.model import Encoder, Decoder, ModelCat\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import timeit\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils.word2vec import seq_to_kmers, get_protein_embedding\n",
    "from gensim.models import Word2Vec\n",
    "from torch.utils import data as torch_data\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0b765",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db220de",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), \"Must have avaliable gpu\"\n",
    "\n",
    "class CFG :\n",
    "    # train dataset and test dataset\n",
    "    traindata_path = './data/traindata_finetuning_example.csv'\n",
    "    testdata_path = './data/testdata_finetuning_example.csv'\n",
    "    # epoch\n",
    "    EPOCHES = 100\n",
    "    # batch size\n",
    "    BATCH_SIZE = 30\n",
    "    \n",
    "    # learning rate\n",
    "    lr = 1e-4\n",
    "    # weight_decay\n",
    "    weight_decay = 1e-4\n",
    "    \n",
    "    # suffix of log/model filename\n",
    "    modelsave_file_suffix = 'funetuning_epoch.pt'\n",
    "    result_file_suffix = 'funetuning_log.txt'\n",
    "    \n",
    "    # create log file\n",
    "    result_file_path = './results/log/funetuning_log/'\n",
    "    # save_best_model(depends on AUC)\n",
    "    best_model_savepath = \"./model/model_funetuning/\"\n",
    "\n",
    "    \n",
    "    # use wandb(https://wandb.ai/)?\n",
    "    IFwandb = False\n",
    "    # data root\n",
    "    DATA_ROOT = r'./data/'\n",
    "    # save unlabel data that may be positive\n",
    "    U_m_P_savepath = r\"./data/U_m_P/\"\n",
    "    # word2vec model path\n",
    "    word2vec_path = './model/model_pretrained/word2vec_pretrained.model'\n",
    "    # pre_trained model path , if given None, training from scratch\n",
    "    state_dict_path = './model/model_pretrained/PU-EPP_pretrained.pt'\n",
    "    # Number CUDA Devices:\n",
    "    gpu_number = torch.cuda.device_count()\n",
    "    # DEVICE\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "\n",
    "    \n",
    "    \n",
    "    # block layers\n",
    "    layer_num = 12\n",
    "    # The last dimension of the protein data\n",
    "    protein_dim = 100\n",
    "    # The last dimension of the compound data\n",
    "    atom_dim = 46\n",
    "    # hidden dimension\n",
    "    hid_dim = 128\n",
    "    # norm_shape: layernorm parameter\n",
    "    norm_shape = 128\n",
    "    # ====================================================\n",
    "    # to create trainreader\n",
    "    # ====================================================\n",
    "    # if use pu learning\n",
    "    ifpu = True\n",
    "    # if use label smoothing\n",
    "    ifsmoothing = True\n",
    "\n",
    "    # start deleting data when auc value is greater than del_threshold\n",
    "    del_threshold=0.9\n",
    "\n",
    "    quantile = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2e2cc-78fa-4b60-b01c-ed81ddc1f574",
   "metadata": {},
   "source": [
    "## WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c6165-78ad-4bf3-86e2-d2e832d0e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.IFwandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    wandb.init(project='PU-EPP', name='finetuning')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa424f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e64bf",
   "metadata": {},
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84547467",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(CFG.protein_dim, CFG.hid_dim, CFG.norm_shape)\n",
    "decoder = Decoder(CFG.atom_dim, CFG.hid_dim, CFG.norm_shape)\n",
    "model = ModelCat(encoder, decoder, atom_dim=CFG.atom_dim)\n",
    "model = model.to(CFG.DEVICE)\n",
    "model = nn.DataParallel(model, device_ids = list(range(CFG.gpu_number)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0a2e68-9e45-4b41-9c88-82d29bd95272",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(CFG.state_dict_path, map_location=CFG.DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b60b12-fa1b-453b-b8f1-41ff9c49ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.IFwandb:\n",
    "    wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f0327",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a932341",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" create trainer \"\"\"\n",
    "# /utils/builder.py\n",
    "trainer = Trainer(model, CFG) #trainfirst=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0f443",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6674e61",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "(you can use get_shuffle_data to divide the dataset into a testset and a trainset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1931bd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = pd.read_csv(CFG.traindata_path)\n",
    "testset = pd.read_csv(CFG.testdata_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff8bcd",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea834f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = TrainReader(data=trainset,U_m_P_savepath=CFG.U_m_P_savepath,\n",
    "                                word2vec_path=CFG.word2vec_path, ifpu=CFG.ifpu)\n",
    "testdata = TestReader(data=testset, word2vec_path=CFG.word2vec_path)\n",
    "\n",
    "''' if our pretrained word2vec model does not include all the protein data in your dataset, you need to train word2vec model by yourself'''\n",
    "\n",
    "# train_word2vec(list(traindata['Protein'].unique()) + list(testdata['Protein'].unique()), './model/model_pretrained/word2vec_yourself.model') \n",
    "\n",
    "# CFG.word2vec_path = './model/model_pretrained/word2vec_yourself.model' \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(testdata, batch_size=CFG.BATCH_SIZE,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161fef1",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c11afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = CFG.modelsave_file_suffix\n",
    "reshead = 'Epoch\\tTime(sec)\\tLoss_train\\tAUC_dev\\tPre\\tRecall\\tPRC_dev'\n",
    "file_res = CFG.result_file_path+CFG.result_file_suffix\n",
    "if os.path.exists(file_res):\n",
    "    warnings.warn(\"----------------file name duplicate-----------------\")\n",
    "else:\n",
    "    with open(file_res, 'w') as f:\n",
    "        f.write(reshead + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23271d33-460e-40d3-b8a2-b2aa13acec76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cfb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_AUC_dev = 0\n",
    "for epoch in range(CFG.EPOCHES):\n",
    "    print('epoch: ' + str(epoch))\n",
    "    train_dataloader = DataLoader(traindata, batch_size=CFG.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    \"\"\"Start training.\"\"\"\n",
    "    print('Training........................')\n",
    "    torch.cuda.empty_cache()\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    loss_train, U_m_P = trainer.train(train_dataloader)\n",
    "    AUC_dev, precision, recall, PRC_dev = trainer.test(val_dataloader)\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    time = end - start\n",
    "    \n",
    "    reslist = [epoch, time, loss_train, AUC_dev, precision, recall, PRC_dev]\n",
    "    if CFG.IFwandb:\n",
    "        wandb.log({'loss_train':loss_train, \"AUC_dev\":AUC_dev, 'pre':precision, 'recall':recall, 'prc':PRC_dev})\n",
    "    trainer.save_AUCs(reslist, file_res)\n",
    "    if AUC_dev > max_AUC_dev:\n",
    "        trainer.save_model(model, f\"{CFG.best_model_savepath}_epoch{epoch}_{AUC_dev}.pt\")\n",
    "        max_AUC_dev = AUC_dev\n",
    "    print('\\t'.join(map(str, reslist)))\n",
    "\n",
    "    if AUC_dev > 0.85: #changed\n",
    "        print(f\"del {epoch}:{len(U_m_P)}\")\n",
    "        traindata.del_U(epoch, U_m_P)\n",
    "    else:\n",
    "        traindata.reset_T()\n",
    "    if epoch % 5 == 0:\n",
    "        trainer.save_model(model, f\"{CFG.best_model_savepath}_epoch{epoch}_{AUC_dev}.pt\")\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f57580-3edc-451e-bccc-4aa69c6180bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Nov 14 2022, 12:59:47) \n[GCC 9.4.0]"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
