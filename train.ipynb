{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "900c37c1",
   "metadata": {},
   "source": [
    "**For Training**\n",
    "===\n",
    "> -*- coding: utf-8 -*-\n",
    "\n",
    "> Author: xinghd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "294d137c",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0a31dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import Trainer, Predictor, TrainReader,TestReader,PredictReader, data_collate, get_shuffle_data, collate_fn, seed_everything\n",
    "from model.model import Encoder, Decoder, ModelCat\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2860079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "import timeit\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Descriptors\n",
    "from torch import nn\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils.word2vec import seq_to_kmers, get_protein_embedding, train_word2vec\n",
    "from gensim.models import Word2Vec\n",
    "from torch.utils import data as torch_data\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda0b765",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db220de",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available(), \"Must have a avaliable gpu\"\n",
    "\n",
    "class CFG :\n",
    "    IFwandb = False\n",
    "\n",
    "    trainfirst = True # True or False, train model from scratch if True else finetune model\n",
    "    # Data root\n",
    "    DATA_ROOT = r'./data/'\n",
    "    # Save unlabel data that may be positive\n",
    "    U_m_P_savepath = r\"./data/U_m_P/\"\n",
    "    # Word2vec model path\n",
    "    word2vec_path = './model/model_pretrained/word2vec_pretrained.model' \n",
    "    # Pre_trained model path , if given None, training from scratch\n",
    "    state_dict_path = None\n",
    "    # Number CUDA Devices:\n",
    "    gpu_number = torch.cuda.device_count()\n",
    "    # Device\n",
    "    DEVICE = torch.device('cuda:0')\n",
    "    # ====================================================\n",
    "    # Hyperparameters\n",
    "    # ====================================================\n",
    "    # Batch size\n",
    "    BATCH_SIZE = 4\n",
    "    # Epoch\n",
    "    EPOCHES = 100\n",
    "    # Block layers\n",
    "    layer_num = 12\n",
    "    # The last dimension of the protein data\n",
    "    protein_dim = 100\n",
    "    # The last dimension of the compound data\n",
    "    atom_dim = 46\n",
    "    # Hidden dimension\n",
    "    hid_dim = 128\n",
    "    # Norm_shape: layernorm parameter\n",
    "    norm_shape = 128\n",
    "    # ====================================================\n",
    "    # To create trainreader\n",
    "    # ====================================================\n",
    "    # If use pu learning\n",
    "    ifpu = True\n",
    "    # If use label smoothing\n",
    "    ifsmoothing = True\n",
    "    # ====================================================\n",
    "    # To create trainer\n",
    "    # ====================================================\n",
    "    # Learning rate\n",
    "    lr = 1e-4\n",
    "    # Weight_decay\n",
    "    weight_decay = 1e-4\n",
    "    # Start removing potential positives from unlabeled samples when AUC > del_threshold\n",
    "    del_threshold=0.9\n",
    "    \n",
    "    # create result file\n",
    "    result_file_path = './results/log/'\n",
    "    # save_best_model(depends on AUC)\n",
    "    best_model_savepath = \"./model/model_save/\"\n",
    "    # \n",
    "    modelsave_file_suffix = 'example_epoch.pt'\n",
    "    result_file_suffix = 'example_log.txt'\n",
    "    \n",
    "    quantile = 0.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f2e2cc-78fa-4b60-b01c-ed81ddc1f574",
   "metadata": {},
   "source": [
    "## WandB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c6165-78ad-4bf3-86e2-d2e832d0e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.IFwandb:\n",
    "    import wandb\n",
    "    wandb.login()\n",
    "    wandb.init(project='PU-EPP', name='train')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaa424f",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e64bf",
   "metadata": {},
   "source": [
    "### Random Seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3299feb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84547467",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8402f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(CFG.protein_dim, CFG.hid_dim, CFG.norm_shape)\n",
    "decoder = Decoder(CFG.atom_dim, CFG.hid_dim, CFG.norm_shape)\n",
    "model = ModelCat(encoder, decoder, atom_dim=CFG.atom_dim)\n",
    "model = model.to(CFG.DEVICE)\n",
    "model = nn.DataParallel(model, device_ids = list(range(CFG.gpu_number)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b60b12-fa1b-453b-b8f1-41ff9c49ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.IFwandb:\n",
    "    wandb.watch(model, log='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943f0327",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a932341",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model, CFG, trainfirst=CFG.trainfirst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd0f443",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6674e61",
   "metadata": {},
   "source": [
    "### Dataset \n",
    "(you can use get_shuffle_data to divide the dataset into a testset and a trainset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574e32ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pd.read_csv('./data/example_train.csv')\n",
    "testdata = pd.read_csv('./data/example_test.csv')\n",
    "id2seq = json.load(open('./data/example_id2seq.json', 'r')) # To save storage space\n",
    "traindata['Protein'] = traindata['Protein'].map(lambda x: id2seq[x])\n",
    "testdata['Protein'] = testdata['Protein'].map(lambda x: id2seq[x])\n",
    "\n",
    "if CFG.trainfirst: \n",
    "    # if you want to train model from scratch or our pretrained word2vec model does not include all the protein data in your dataset, \n",
    "    # you need to train word2vec model by yourself\n",
    "    train_word2vec(list(traindata['Protein'].unique()) + list(testdata['Protein'].unique()), './model/model_pretrained/word2vec_yourself.model')\n",
    "    # protein data, word2vec model path \n",
    "    CFG.word2vec_path = './model/model_pretrained/word2vec_yourself.model'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbff8bcd",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea834f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = TrainReader(data=traindata,U_m_P_savepath=CFG.U_m_P_savepath,\n",
    "                                word2vec_path=CFG.word2vec_path, ifpu=CFG.ifpu)\n",
    "testdata = TestReader(data=testdata, word2vec_path=CFG.word2vec_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5d34f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(testdata, batch_size=CFG.BATCH_SIZE,collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e161fef1",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c11afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_model = CFG.modelsave_file_suffix\n",
    "reshead = 'Epoch\\tTime(sec)\\tLoss_train\\tAUC_dev\\tPre\\tRecall\\tPRC_dev'\n",
    "file_res = CFG.result_file_path+CFG.result_file_suffix\n",
    "if os.path.exists(file_res):\n",
    "    warnings.warn(\"----------------duplicate filename-----------------\")\n",
    "else:\n",
    "    with open(file_res, 'w') as f:\n",
    "        f.write(reshead + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c48cfb54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_AUC_dev = 0\n",
    "for epoch in range(CFG.EPOCHES):\n",
    "    print('epoch: ' + str(epoch))\n",
    "    train_dataloader = DataLoader(traindata, batch_size=CFG.BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "    \"\"\"Start training.\"\"\"\n",
    "    print('Training........................')\n",
    "    torch.cuda.empty_cache()\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    loss_train, U_m_P = trainer.train(train_dataloader)\n",
    "    AUC_dev, precision, recall, PRC_dev = trainer.test(val_dataloader)\n",
    "\n",
    "    end = timeit.default_timer()\n",
    "    time = end - start\n",
    "    \n",
    "    reslist = [epoch, time, loss_train, AUC_dev, precision, recall, PRC_dev]\n",
    "    if CFG.IFwandb:\n",
    "        wandb.log({'loss_train':loss_train, \"AUC_dev\":AUC_dev, 'pre':precision, 'recall':recall, 'prc':PRC_dev})\n",
    "    trainer.save_AUCs(reslist, file_res)\n",
    "    if AUC_dev > max_AUC_dev:\n",
    "        trainer.save_model(model, f\"{CFG.best_model_savepath}_epoch{epoch}_{AUC_dev}.pt\")\n",
    "        max_AUC_dev = AUC_dev\n",
    "    print('\\t'.join(map(str, reslist)))\n",
    "\n",
    "    if AUC_dev > 0.85: #changed\n",
    "        print(f\"del {epoch}:{len(U_m_P)}\")\n",
    "        traindata.del_U(epoch, U_m_P)\n",
    "    else:\n",
    "        traindata.reset_T()\n",
    "    if epoch % 5 == 0:\n",
    "        trainer.save_model(model, f\"{CFG.best_model_savepath}_epoch{epoch}_{AUC_dev}.pt\")\n",
    "    torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Med",
   "language": "python",
   "name": "med"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
